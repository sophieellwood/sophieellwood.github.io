---
title: "Variational autoender with Signed Distance Functions (SDFs) in Jax"
date: 2025-11-21
draft: false
description: "a description"
tags: ["example", "tag"]
showAuthor: false
showDate: false
showReadingTime: false
showWordCount: false
showHero: false
---

[Code](https://github.com/sophieellwood/Variational-Autoender-with-Signed-Distance-Functions-Jax/blob/main/VAE_DeepSDF.ipynb)

**Part I**

A VAE trained using a convolutional AE and vanilla Decoder. The model uses ELBO loss, consisting of a reconstruction term and KL divergence.
This model _should_ work with a DeepSDF decoder (included in the code). The decoder should take an input coordinate _in addition to_ 
the latent space vector generated by the encoder. 
However, in practice, this gave poor reconstruction, where the predicted values did not span the whole -1 to 1 range. This is likely an issue with the KL
divergence, as the sampled distribution may be too small.
Instead, here are some results on the test set with a vanilla decoder, and so the SDFs are treated similarly to image values. (Increasing training iterations would give more accurate results).
<div align="center">
<img width="1044" height="282" alt="image" src="https://github.com/user-attachments/assets/839d1615-89c4-4e8c-a86e-135ff878f2ea" />
</div>

We can see that sampling the latent space gives 'imaginary' numbers that still resemble actual values. This is due to using a distribution
to represent the latent space, instead of mapping to a single vector.
<div align="center">
<img width="533" height="483" alt="image" src="https://github.com/user-attachments/assets/513b5ede-c818-42dd-bdd5-49b1ae7306a8" />
</div>

Interpolation also works well.
<div align="center">
<img width="1198" height="122" alt="image" src="https://github.com/user-attachments/assets/764e5029-456b-4636-8779-ea7ddac7bd88" />
</div>

**Part II**

A vanilla encoder transforms input SDFs into latent space vectors. DeepSDF, as the decoder, takes in a coordinate in 2d space and the latent, producing a predicted SDF.
MSE loss is used to optimize the Autoencoder.

Reconstruction:
<div align="center">
<img width="878" height="248" alt="image" src="https://github.com/user-attachments/assets/2aff0556-20c3-4188-8a83-9551b819f8a3" />
</div>

Interpolation between two SDFs randomly selected from the test set:
<div align="center">
<img width="2162" height="364" alt="image" src="https://github.com/user-attachments/assets/4e84deb6-0735-4955-8b14-b4503097541a" />
</div>

Sampling the latent space:
<div align="center">
<img width="371" height="282" alt="image" src="https://github.com/user-attachments/assets/c66dc00e-2d2c-45ed-b9d5-ace52ebfb464" />
</div>
Testing out different latent sizes:
<div align="center">
<img width="302" height="290" alt="image" src="https://github.com/user-attachments/assets/a643dfcc-63d4-40fd-87f9-380ee6b8c72d" />
</div>

**This code was created with the help of the following tutorials and repos:**
- [Tutorial 9 (JAX): Deep Autoencoders](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial9/AE_CIFAR10.html)
- [MetaSDF](https://github.com/vsitzmann/metasdf/blob/master/MNISTHypernetworksDemo.ipynb)
- [Fashion MNIST](https://github.com/najeebuddinm98/vae_fashionmnist/blob/main/VAE_fashionmnist.ipynb)
- [Debug a variational autoencoder (VAE)](https://docs.jaxstack.ai/en/stable/digits_vae.html)
- [DeepSDF](https://github.com/facebookresearch/DeepSDF)

